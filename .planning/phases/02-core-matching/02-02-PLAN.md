---
phase: 02-core-matching
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - api/ask.ts
  - src/lib/mock-api.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "User question is converted to an embedding and matched against lyrics via pgvector similarity search"
    - "LLM selects the best lyric from top 3 candidates using few-shot prompted emotional matching"
    - "When no candidates match or LLM returns NO_MATCH, a soft poetic fallback message is returned"
    - "Response is a single lyric (1-2 lines), nothing else — enforced in prompt"
    - "Repeated identical questions can return different lyrics (temperature > 0)"
  artifacts:
    - path: "api/ask.ts"
      provides: "Full matching pipeline: embedding -> pgvector search -> LLM selection -> fallback"
      contains: "match_lyrics"
    - path: "src/lib/mock-api.ts"
      provides: "Mock API reflecting real matching patterns with varied responses"
      contains: "FALLBACK_MESSAGES"
    - path: "package.json"
      provides: "@supabase/supabase-js dependency"
      contains: "@supabase/supabase-js"
  key_links:
    - from: "api/ask.ts"
      to: "OpenAI embeddings API"
      via: "openai.embeddings.create with text-embedding-3-small"
      pattern: "text-embedding-3-small"
    - from: "api/ask.ts"
      to: "Supabase pgvector"
      via: "supabase.rpc('match_lyrics')"
      pattern: "rpc\\('match_lyrics'"
    - from: "api/ask.ts"
      to: "OpenAI chat completions"
      via: "gpt-4o-mini with few-shot examples for final selection"
      pattern: "gpt-4o-mini"
    - from: "api/ask.ts"
      to: "Fallback pool"
      via: "FALLBACK_MESSAGES array with random selection"
      pattern: "FALLBACK_MESSAGES"
---

<objective>
Implement the core lyric matching pipeline in api/ask.ts: embedding generation, pgvector similarity search, LLM final selection with few-shot examples, and poetic fallback handling.

Purpose: This is the heart of Phase 2 — transforming the generic Phase 1 OpenAI call into a semantic matching engine that understands emotional context. The pipeline: question -> embedding -> pgvector top 3 -> LLM picks best match -> return lyric (or poetic fallback).

Output: Rewritten api/ask.ts with full matching pipeline, updated mock-api.ts with realistic responses, @supabase/supabase-js installed.
</objective>

<execution_context>
@/Users/august/.claude/get-shit-done/workflows/execute-plan.md
@/Users/august/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-core-matching/02-CONTEXT.md
@.planning/phases/02-core-matching/02-RESEARCH.md
@.planning/phases/02-core-matching/02-01-SUMMARY.md
@api/ask.ts
@src/lib/mock-api.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Supabase client and rewrite api/ask.ts with full matching pipeline</name>
  <files>package.json, api/ask.ts</files>
  <action>
**Step 1: Install dependency**

```bash
npm install @supabase/supabase-js
```

**Step 2: Rewrite api/ask.ts**

Preserve ALL existing Phase 1 infrastructure (rate limiting, sanitization, error handling, IP extraction). Replace ONLY the OpenAI chat completion call (step 6 in current code) with the full matching pipeline.

The existing code structure to KEEP intact:
- Import and inline sanitization logic (lines 1-38)
- Lazy OpenAI singleton (lines 42-58)
- Lazy rate limiter singletons (lines 60-83)
- Handler: method check, IP extraction, rate limiting, body parsing, sanitization (lines 87-129)
- Error handling with timeout detection (lines 153-163)

ADD these new components:

**A. Supabase lazy singleton** (after OpenAI singleton, same pattern):
```typescript
import { createClient, SupabaseClient } from '@supabase/supabase-js';

let supabaseClient: SupabaseClient | null = null;

function getSupabase(): SupabaseClient {
  if (!supabaseClient) {
    const url = process.env.SUPABASE_URL;
    const key = process.env.SUPABASE_ANON_KEY;
    if (!url || !key) {
      throw new Error('SUPABASE_URL and SUPABASE_ANON_KEY are required');
    }
    supabaseClient = createClient(url, key, {
      auth: { persistSession: false }  // serverless: no session persistence
    });
  }
  return supabaseClient;
}
```

Use SUPABASE_ANON_KEY (not service role key) per research pitfall #6.

**B. Fallback message pool** (Claude-authored, soft & poetic per user decision):
```typescript
const FALLBACK_MESSAGES = [
  "Some feelings are still waiting for their song.",
  "Not every question has found its lyric yet.",
  "Even Taylor doesn't have words for everything.",
  "This one's still between the lines.",
  "Sometimes silence says more than lyrics can."
];

function getRandomFallback(): string {
  return FALLBACK_MESSAGES[Math.floor(Math.random() * FALLBACK_MESSAGES.length)];
}
```

**C. Replace step 6 (OpenAI call) with full pipeline:**

```typescript
// 6. Generate embedding for user question
const embeddingResponse = await getOpenAI().embeddings.create({
  model: 'text-embedding-3-small',  // Locked model — do NOT mix with ada-002
  input: question
});
const queryEmbedding = embeddingResponse.data[0].embedding;

// 7. Find top 3 similar lyrics via pgvector
const { data: candidates, error: dbError } = await getSupabase().rpc('match_lyrics', {
  query_embedding: queryEmbedding,
  match_threshold: 0.70,  // Start conservative, tune based on testing
  match_count: 3
});

if (dbError) throw dbError;

// 8. Handle no candidates (all below threshold)
if (!candidates || candidates.length === 0) {
  res.status(200).json({ lyric: getRandomFallback() });
  return;
}

// 9. LLM selects best match from candidates with few-shot examples
const completion = await getOpenAI().chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [
    {
      role: 'system',
      content: `You match life questions to Taylor Swift lyrics. Feel the emotional weight of the question — not just the words, but the ache or hope behind them. Return ONLY the lyric text (1-2 lines, nothing else). If none of the candidates truly speak to the question, respond with exactly "NO_MATCH".`
    },
    // Few-shot example 1: self-doubt -> empowerment
    {
      role: 'user',
      content: `Question: "How do I stop caring what people think of me?"
Candidates:
1. "I'm the only one of me, baby, that's the fun of me"
2. "It's me, hi, I'm the problem, it's me"
3. "Long live the walls we crashed through"`
    },
    { role: 'assistant', content: `I'm the only one of me, baby, that's the fun of me` },
    // Few-shot example 2: heartbreak -> raw pain
    {
      role: 'user',
      content: `Question: "Why does losing someone hurt this much?"
Candidates:
1. "You call me up again just to break me like a promise"
2. "We are never ever getting back together"
3. "I'm the only one of me, baby, that's the fun of me"`
    },
    { role: 'assistant', content: `You call me up again just to break me like a promise` },
    // Few-shot example 3: NO_MATCH demonstration
    {
      role: 'user',
      content: `Question: "What's the best programming language?"
Candidates:
1. "Shake it off, shake it off"
2. "This is me trying"
3. "We are never ever getting back together"`
    },
    { role: 'assistant', content: `NO_MATCH` },
    // Current query
    {
      role: 'user',
      content: `Question: "${question}"
Candidates:
${candidates.map((c: any, i: number) => `${i + 1}. "${c.lyric_text}"`).join('\n')}`
    }
  ],
  temperature: 0.6,  // Emotional variation — "feels alive" per user decision
  max_tokens: 100
});

const lyric = completion.choices[0]?.message?.content?.trim();

// 10. Handle NO_MATCH or empty response
if (!lyric || lyric === 'NO_MATCH') {
  res.status(200).json({ lyric: getRandomFallback() });
  return;
}

// 11. Return matched lyric
res.status(200).json({ lyric });
```

Key decisions per user's locked requirements:
- Temperature 0.6 (Claude's discretion within 0.5-0.7 range) — "feels alive"
- 3 few-shot examples: self-doubt, heartbreak, and NO_MATCH demonstration
- Tone: poetic & intuitive system prompt — "feel the emotional weight"
- Response is lyric only, nothing else (enforced in system prompt)
- Max lyric length 1-2 lines (enforced in system prompt)
- No post-hoc validation against dataset — trust the prompt
- Similarity threshold 0.70 to start (Claude's discretion, per research recommendation)

The full file structure should be:
1. Imports (VercelRequest/Response, supabase-js, OpenAI)
2. Sanitization logic (unchanged from Phase 1)
3. Lazy singletons: OpenAI, Supabase, Rate limiters
4. Fallback pool + helper
5. Handler function with complete pipeline
  </action>
  <verify>
- `npm install` completes without errors
- `@supabase/supabase-js` appears in package.json dependencies
- `api/ask.ts` contains: `createClient` import, `getSupabase()`, `text-embedding-3-small`, `rpc('match_lyrics')`, `FALLBACK_MESSAGES`, `NO_MATCH` handling
- `api/ask.ts` still contains: rate limiting, sanitization, IP extraction, error handling (Phase 1 preserved)
- `npm run build` succeeds (TypeScript compiles)
  </verify>
  <done>
api/ask.ts implements full matching pipeline: question -> embedding -> pgvector top 3 -> LLM few-shot selection -> lyric or poetic fallback. All Phase 1 security infrastructure (rate limiting, sanitization) preserved.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update mock API with realistic matching responses</name>
  <files>src/lib/mock-api.ts</files>
  <action>
Update `src/lib/mock-api.ts` to reflect the new matching behavior for local development:

1. **Replace single hardcoded lyric with a small pool of lyrics** — randomly selected to simulate the "feels alive" behavior (temperature > 0 means same question can get different lyrics):

```typescript
const MOCK_LYRICS = [
  "Long story short, I survived",
  "It's me, hi, I'm the problem, it's me",
  "I'm the only one of me, baby, that's the fun of me",
  "This is me trying",
  "Shake it off, shake it off"
];
```

2. **Add the same fallback message pool** from api/ask.ts — simulate the fallback path for short/vague inputs:

```typescript
const FALLBACK_MESSAGES = [
  "Some feelings are still waiting for their song.",
  "Not every question has found its lyric yet.",
  "Even Taylor doesn't have words for everything.",
  "This one's still between the lines.",
  "Sometimes silence says more than lyrics can."
];
```

3. **Simulate fallback for very short questions** (< 10 chars after trim) — returns a fallback message instead of a lyric. This helps frontend development test both paths.

4. **Keep existing behavior:** 800-1200ms delay, empty/overlength validation, error messages unchanged.

5. **For valid questions >= 10 chars:** Return a random lyric from MOCK_LYRICS pool.

6. **For valid questions < 10 chars:** Return a random fallback from FALLBACK_MESSAGES (simulates "no good match" path).

This gives frontend developers both paths to test: lyric responses and poetic fallbacks.
  </action>
  <verify>
- `src/lib/mock-api.ts` contains MOCK_LYRICS array with multiple lyrics
- `src/lib/mock-api.ts` contains FALLBACK_MESSAGES array
- Mock returns different responses for repeated calls (random selection)
- Mock returns fallback messages for short inputs
- `npm run build` succeeds
  </verify>
  <done>
Mock API returns varied lyrics from a pool (simulating temperature > 0 behavior) and poetic fallback messages for edge cases, enabling frontend development of both response paths.
  </done>
</task>

</tasks>

<verification>
- api/ask.ts has complete pipeline: embedding -> pgvector -> LLM selection -> fallback
- System prompt enforces "lyric only, 1-2 lines, nothing else"
- Few-shot examples demonstrate emotional matching (not keyword matching) and NO_MATCH
- Temperature is > 0 (set to 0.6) for response variation
- Fallback messages are soft and poetic (not error-like)
- Phase 1 security infrastructure fully preserved (rate limiting, sanitization, error handling)
- @supabase/supabase-js is installed
- Mock API reflects both lyric and fallback response paths
- `npm run build` succeeds
</verification>

<success_criteria>
The matching engine is implemented: questions are converted to embeddings, matched against lyrics via pgvector, and the best lyric is selected by gpt-4o-mini with emotional few-shot calibration. Fallback handling returns poetic messages when no match is found. Mock API enables local development of both paths.
</success_criteria>

<output>
After completion, create `.planning/phases/02-core-matching/02-02-SUMMARY.md`
</output>
